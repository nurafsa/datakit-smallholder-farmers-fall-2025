{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edad6b0-81ca-458f-871a-f7488027e29d",
   "metadata": {},
   "source": [
    "# PREDICT VALUE FOR MISSING QUESTION TOPIC WITH RELABELLING V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a5ef8-99bd-43a8-83a0-b4c184034fb0",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c538316c-9abf-479f-8e67-0b56afd4637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 20:06:25.608800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764839185.689232   20574 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764839185.711620   20574 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764839186.068293   20574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764839186.068329   20574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764839186.068331   20574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764839186.068333   20574 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_MIN_GPU_MULTIPROCESSOR_COUNT'] = '6' # Needed so I can use my old GPU with the new one\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' # Turns off oneDNN custom operations\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # Hides message regarding TensorFlow optimization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2991ae-3112-4dde-8da6-0d5b7daa2d32",
   "metadata": {},
   "source": [
    "## Import CSV File & Remove Duplicates\n",
    "NB:\n",
    "\n",
    "- 'question_topic_valid.csv' represents records from the original dataset\n",
    "- 'question_topic' was not empty while 'question_topic_null.csv' are records with missing values for 'question_topic'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbb4951-125c-42ab-9767-4b03b73c326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import patitioned libraries of original dataset\n",
    "# These datasets were created in another notebook (see 'dataset_partition.ipynb')\n",
    "df_topic_exists = pd.read_csv('../data/question_topic_valid_relabel_r1.csv', usecols=[0,2,3,4,13,14]) # Import only essential columns\n",
    "df_topic_null = pd.read_csv('../data/question_topic_null.csv')\n",
    "\n",
    "# Drops duplicate 'question_content' due to multiple 'question_id' in the dataset\n",
    "df_topic_exists.drop_duplicates(subset='question_id',inplace=True)\n",
    "df_topic_exists.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feafbd64-c133-4cf5-b57a-e331a75582b7",
   "metadata": {},
   "source": [
    "## Tokenize The Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243fcdda-d3c0-4493-bfe0-09c99ac6a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_sentences(col):\n",
    "    sentence_list = []\n",
    "    for text in col:\n",
    "        splitted_text = text.lower().split()\n",
    "        sentence_list.append(splitted_text)\n",
    "    return sentence_list\n",
    "\n",
    "sentences_topic_exist = list_of_sentences(df_topic_exists.question_content)\n",
    "sentences_topic_null = list_of_sentences(df_topic_null.question_content)\n",
    "\n",
    "# Initiate the tokenizer with a out_of_vocabulary token \n",
    "tokenizer_X = Tokenizer(oov_token=\"<OOV>\")\n",
    "\n",
    "# Generate word indexes for all sentences \n",
    "tokenizer_X.fit_on_texts(sentences_topic_exist+sentences_topic_null)\n",
    "\n",
    "# Generate separate sequences for both with topic values and missing values\n",
    "X = tokenizer_X.texts_to_sequences(sentences_topic_exist)\n",
    "X_topic_null = tokenizer_X.texts_to_sequences(sentences_topic_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6956b-9f6c-4a3d-8767-807e1aeb5ce1",
   "metadata": {},
   "source": [
    "## Determine Word Counts & Maximum Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f803052c-b3ca-4469-92e3-bd784941bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words from all questions is 1292953.\n",
      "The highest number of words in any sentence is 197.\n"
     ]
    }
   ],
   "source": [
    "print(f'The total number of words from all questions is {len(tokenizer_X.word_counts)}.')\n",
    "\n",
    "max_len = 0\n",
    "for l in X + X_topic_null: # Include questions from the entire dataset\n",
    "    if len(l) > max_len:\n",
    "        max_len = len(l)\n",
    "\n",
    "print(f'The highest number of words in any sentence is {max_len}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4942d2bf-9b4c-4dd7-9e4f-240485a8d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 40000     # Use 40000 most frequent words from the total of 1292953 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5993d23-c057-4b78-b556-5cd8d536268b",
   "metadata": {},
   "source": [
    "## Create Train & Test Datasets & Prepare For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315e1535-0d21-40bb-8425-885f79bc7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, df_topic_exists.question_topic, test_size=0.2,\n",
    "                                                                stratify=df_topic_exists.question_topic, random_state=42)\n",
    "\n",
    "# Format X and y for model\n",
    "X_train = np.array(sequence.pad_sequences(X_train_df, maxlen=max_len))\n",
    "X_test = np.array(sequence.pad_sequences(X_test_df, maxlen=max_len))\n",
    "\n",
    "y_train_one_hot = pd.get_dummies(y_train_df)\n",
    "y_train = y_train_one_hot.to_numpy()\n",
    "y_test_one_hot = pd.get_dummies(y_test_df)\n",
    "y_test = y_test_one_hot.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb8495-742f-4d35-ab60-7ffd05c21821",
   "metadata": {},
   "source": [
    "## Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f680d6e-d724-4ba7-b20d-fdd862fbf8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer block class\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.01):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e8d561-5861-4b89-86e1-c73ef6064639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764840329.802405   20574 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5518 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0000 00:00:1764840329.809141   20574 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 2857 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Define the model with an embedding layer, transformer block, and output layer\n",
    "embed_dim = 32 # Embedding dimension for each word vector\n",
    "num_heads = 4  # The number of attention heads in the multi-head attention layer\n",
    "ff_dim = 64    # Number of units in the feed forward layer\n",
    "\n",
    "inputs = layers.Input(shape=(max_len,))\n",
    "\n",
    "embedding_layer = layers.Embedding(input_dim=max_features, output_dim=embed_dim)\n",
    "out = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "out = transformer_block(out, training=True)\n",
    "out = layers.GlobalAveragePooling1D()(out)\n",
    "out = layers.Dropout(0.1)(out)\n",
    "out = layers.Dense(20, activation='relu')(out)\n",
    "out = layers.Dropout(0.1)(out)\n",
    "outputs = layers.Dense(148, activation='softmax')(out)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73569ba3-a84f-4fe5-b6cc-0d6145c09d6a",
   "metadata": {},
   "source": [
    "## Compile & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "945f82e3-e324-47d5-a88e-835800da38c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 20:25:36.497238: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2115021944 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764840343.714421   21016 service.cc:152] XLA service 0x7f7b9c00a760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764840343.714485   21016 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "I0000 00:00:1764840343.714490   21016 service.cc:160]   StreamExecutor device (1): NVIDIA GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "I0000 00:00:1764840344.554492   21016 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "I0000 00:00:1764840364.340188   21016 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 45ms/step - accuracy: 0.8410 - loss: 0.6370 - val_accuracy: 0.9015 - val_loss: 0.3068\n",
      "Epoch 2/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 39ms/step - accuracy: 0.8957 - loss: 0.3383 - val_accuracy: 0.9029 - val_loss: 0.2787\n",
      "Epoch 3/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 39ms/step - accuracy: 0.8989 - loss: 0.3077 - val_accuracy: 0.9033 - val_loss: 0.2716\n",
      "Epoch 4/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 39ms/step - accuracy: 0.9018 - loss: 0.2891 - val_accuracy: 0.9040 - val_loss: 0.2706\n",
      "Epoch 5/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 39ms/step - accuracy: 0.9036 - loss: 0.2762 - val_accuracy: 0.9039 - val_loss: 0.2720\n",
      "Epoch 6/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 39ms/step - accuracy: 0.9054 - loss: 0.2657 - val_accuracy: 0.9033 - val_loss: 0.2672\n",
      "Epoch 7/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - accuracy: 0.9065 - loss: 0.2582 - val_accuracy: 0.9040 - val_loss: 0.2705\n",
      "Epoch 8/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 39ms/step - accuracy: 0.9080 - loss: 0.2512 - val_accuracy: 0.9040 - val_loss: 0.2737\n",
      "Epoch 9/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.2454 - val_accuracy: 0.9042 - val_loss: 0.2835\n",
      "Epoch 10/10\n",
      "\u001b[1m5243/5243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - accuracy: 0.9101 - loss: 0.2404 - val_accuracy: 0.9037 - val_loss: 0.2842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7d8d291950>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=512, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17dd374-2685-4c79-86ea-3e9bdc6407f5",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b54c3f34-1aeb-4524-bcb5-92f63cd4f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26212/26212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 7ms/step - accuracy: 0.9044 - loss: 0.2809\n",
      "Test Accuracy: 0.9044293761253357\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83c435-514d-414d-8502-f4137e57f446",
   "metadata": {},
   "source": [
    "## Extract Failed Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807fcf2b-18d8-4695-9d1d-ce6a273290a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26212/26212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Store in a list the column names for one-hot encoding (question_topic)\n",
    "one_hot_columns = list(y_test_one_hot.columns)\n",
    "\n",
    "# Store predictions for X_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Add predictions column to y_test_df\n",
    "y_test_df = y_test_df.to_frame()\n",
    "y_test_df['predictions'] = [one_hot_columns[i] for i in np.argmax(y_pred, axis=1)]\n",
    "\n",
    "# Merge index associated rows from the original source dataset along with the predictions \n",
    "test_df = pd.merge(df_topic_exists, y_test_df, left_index=True, right_index=True)\n",
    "\n",
    "# Create new dataframe that stores rows from test df where predictions were incorrect plus adds the predictions column\n",
    "false_predictions = pd.DataFrame()\n",
    "for i,v in test_df.iterrows():\n",
    "    if v.question_topic_x != v.predictions:\n",
    "        row = pd.DataFrame({'question_language' : [v.question_language], 'question_content' : [v.question_content],\n",
    "                            'question_user_status' : [v.question_user_status], 'question_user_country_code' : [v.question_user_country_code],\n",
    "                            'question_topic': [v.question_topic_x], 'predictions' : [v.predictions]\n",
    "                            })\n",
    "        false_predictions = pd.concat([false_predictions, row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01507607-286b-4f4b-94a4-b8d4add2b628",
   "metadata": {},
   "source": [
    "# Export Test df For Predictions Versus Actual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02586d05-fa9f-4a02-8847-fb6e5faaf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../data/prediction_vs_actual_topic_r1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace49208-9f2c-4afe-b1f7-78da0638fc4a",
   "metadata": {},
   "source": [
    "## Check For Any Indicators For Failure Rate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92605c71-b205-4886-9f8c-8a5b2ce50567",
   "metadata": {},
   "source": [
    "The overall failure rate for the test data set after relabelling existing question topics is 9.56%. Improvement after relabelling is just under 0.2%.\n",
    "\n",
    "For question_language, and question_user_status, the percentage failure rates are fairly consistent with the overall failure rate.\n",
    "For question_user_country_code, gb is now twice the average compared to the overall failure rate of the test dataset.\n",
    "\n",
    "For the question_topic of 'plant', the failure rate is still 42.55% despite there being 27895 samples in the test dataset. As 'plant' was asummed to mean the act of 'planting' not many records would have been updated. If plant is a generic label for all plants then further relabelling is likely to bring this error rate down.\n",
    "\n",
    "The topics in question_topic with lower failure rates tended to have higher counts although there were some values that performed well despite the very small sample size. The topic 'rabbit' still performed the best although the failure rate increased slightly from 2.62% to 2.71%. There were 17 topics with a sample size less than 30 that could not make even 1 correct prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cac0a96-50a4-45de-a6f6-5ec092e79ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data % failure rate by question_language\n",
      "eng    9.628835\n",
      "swa    9.992346\n",
      "nyn    6.224110\n",
      "lug    9.276320\n",
      "Name: count, dtype: float64\n",
      "\n",
      "The test data % failure rate by question_user_country_code\n",
      "ke    11.482577\n",
      "ug     8.556559\n",
      "tz     7.339409\n",
      "gb    20.000000\n",
      "Name: count, dtype: float64\n",
      "\n",
      "The test data % failure rate by question_user_status\n",
      "live          9.225930\n",
      "zombie       10.434853\n",
      "destroyed    10.146577\n",
      "blocked       9.633006\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The test data % failure rate by {(false_predictions.question_language.value_counts() / test_df.question_language.value_counts()) * 100}\\n')\n",
    "print(f'The test data % failure rate by {(false_predictions.question_user_country_code.value_counts() / test_df.question_user_country_code.value_counts()) * 100}\\n')\n",
    "print(f'The test data % failure rate by {(false_predictions.question_user_status.value_counts() / test_df.question_user_status.value_counts()) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3681182e-40b8-4790-8532-e3188a7d8da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 60 failure rates \n",
      "       question_topic  failed_prediction  total  percentage_failed\n",
      "0           chickpea                 14     14         100.000000\n",
      "1          asparagus                 11     11         100.000000\n",
      "2           snap-pea                  9      9         100.000000\n",
      "3              chard                 17     17         100.000000\n",
      "4        castor-bean                  6      6         100.000000\n",
      "5                rye                  5      5         100.000000\n",
      "6              lupin                  5      5         100.000000\n",
      "7            apricot                  6      6         100.000000\n",
      "8           mulberry                  3      3         100.000000\n",
      "9           leucaena                  3      3         100.000000\n",
      "10             vetch                  4      4         100.000000\n",
      "11        blackberry                  4      4         100.000000\n",
      "12      purple-vetch                  1      1         100.000000\n",
      "13           setaria                  3      3         100.000000\n",
      "14         cranberry                  1      1         100.000000\n",
      "15            celery                 10     10         100.000000\n",
      "16        gooseberry                 26     27          96.296296\n",
      "17              flax                 50     52          96.153846\n",
      "18             peach                 92    106          86.792453\n",
      "19  black-nightshade                 28     34          82.352941\n",
      "20         courgette                 29     38          76.315789\n",
      "21         safflower                103    144          71.527778\n",
      "22        guinea-pig                 23     33          69.696970\n",
      "23              pear                152    219          69.406393\n",
      "24            clover                 86    138          62.318841\n",
      "25             guava                157    275          57.090909\n",
      "26            acacia                 70    125          56.000000\n",
      "27         caliandra                  5      9          55.555556\n",
      "28            cereal               1560   2957          52.756172\n",
      "29    collard-greens                 55    105          52.380952\n",
      "30             olive                413    819          50.427350\n",
      "31            radish                 38     76          50.000000\n",
      "32            barley                 33     67          49.253731\n",
      "33            garlic                340    692          49.132948\n",
      "34             plant              13287  27679          48.003902\n",
      "35           lettuce                 11     24          45.833333\n",
      "36     finger-millet                 68    150          45.333333\n",
      "37          amaranth                 55    124          44.354839\n",
      "38            sesame                 26     59          44.067797\n",
      "39       cauliflower                 11     25          44.000000\n",
      "40             sisal                144    330          43.636364\n",
      "41            cyprus                 27     62          43.548387\n",
      "42      napier-grass                808   1897          42.593569\n",
      "43             wheat               2023   4963          40.761636\n",
      "44       sudan-grass                  8     20          40.000000\n",
      "45          plantain               1307   3386          38.600118\n",
      "46            greens                 88    234          37.606838\n",
      "47      sweet-potato                946   2635          35.901328\n",
      "48               oat                 20     58          34.482759\n",
      "49              leek                  4     12          33.333333\n",
      "50           parsley                 68    212          32.075472\n",
      "51          snow-pea                 67    211          31.753555\n",
      "52        eucalyptus                146    462          31.601732\n",
      "53               cat                367   1168          31.421233\n",
      "54             lemon                 80    260          30.769231\n",
      "55            locust                 20     66          30.303030\n",
      "56            pigeon                442   1462          30.232558\n",
      "57            chilli                419   1467          28.561691\n",
      "58             grass                907   3202          28.326046\n",
      "59            squash                 60    212          28.301887\n",
      "\n",
      "The bottom 60 failure rates \n",
      "        question_topic  failed_prediction   total  percentage_failed\n",
      "88             turkey                170    1102          15.426497\n",
      "89                pea                237    1587          14.933837\n",
      "90           cucumber                 29     198          14.646465\n",
      "91   butternut-squash                 96     675          14.222222\n",
      "92         watermelon               1104    7870          14.027954\n",
      "93          mung-bean                 67     491          13.645621\n",
      "94         strawberry                 29     213          13.615023\n",
      "95          vegetable                787    5950          13.226891\n",
      "96              melon                293    2236          13.103757\n",
      "97             millet                577    4675          12.342246\n",
      "98         corriander                  7      57          12.280702\n",
      "99          livestock                841    7002          12.010854\n",
      "100            cotton               1465   12299          11.911538\n",
      "101              tree                721    6212          11.606568\n",
      "102              soya                164    1422          11.533052\n",
      "103       boma-rhodes                 24     212          11.320755\n",
      "104           chicken               9428   86213          10.935706\n",
      "105             apple                102     946          10.782241\n",
      "106           poultry               5831   54382          10.722298\n",
      "107             cocoa                 61     598          10.200669\n",
      "108               dog                293    3109           9.424252\n",
      "109              chia                 18     191           9.424084\n",
      "110           pumpkin                115    1221           9.418509\n",
      "111             grape                 10     110           9.090909\n",
      "112             sheep                732    8174           8.955224\n",
      "113            ginger                128    1461           8.761123\n",
      "114          beetroot                 35     405           8.641975\n",
      "115     passion-fruit                638    7433           8.583345\n",
      "116           tobacco                 87    1015           8.571429\n",
      "117        sugar-cane                421    4986           8.443642\n",
      "118            potato               1702   20256           8.402449\n",
      "119               pig               2079   24764           8.395251\n",
      "120              taro                 47     574           8.188153\n",
      "121         sunflower                259    3228           8.023544\n",
      "122        pigeon-pea                 37     465           7.956989\n",
      "123              crop               1443   18322           7.875778\n",
      "124          mushroom                110    1420           7.746479\n",
      "125              bean               2808   36598           7.672550\n",
      "126           spinach                136    1811           7.509663\n",
      "127           avocado                205    2840           7.218310\n",
      "128        cashew-nut                 83    1167           7.112254\n",
      "129       french-bean                 36     564           6.382979\n",
      "130            carrot                224    3752           5.970149\n",
      "131              goat               1419   23897           5.937984\n",
      "132              fish                285    4906           5.809213\n",
      "133         pineapple                 82    1414           5.799151\n",
      "134               tea                249    4581           5.435494\n",
      "135            banana                800   14752           5.422993\n",
      "136            peanut                400    7377           5.422258\n",
      "137               bee                309    5816           5.312930\n",
      "138            coffee                925   17442           5.303291\n",
      "139           cassava                277    5476           5.058437\n",
      "140              kale                284    5636           5.039035\n",
      "141             onion                730   16296           4.479627\n",
      "142           cabbage                487   12404           3.926153\n",
      "143            tomato               2410   65286           3.691450\n",
      "144            cattle               2919   85019           3.433350\n",
      "145              rice                498   15026           3.314255\n",
      "146             maize               3059  107274           2.851576\n",
      "147            rabbit                458   16890           2.711664\n"
     ]
    }
   ],
   "source": [
    "question_topic_failed = false_predictions.question_topic.value_counts().rename_axis('question_topic').reset_index(name='failed_prediction')\n",
    "question_topic_total = test_df.question_topic_x.value_counts().rename_axis('question_topic').reset_index(name='total')\n",
    "question_topic = pd.merge(question_topic_failed, question_topic_total, how='inner')\n",
    "question_topic['percentage_failed'] = (question_topic['failed_prediction'] / question_topic['total']) * 100\n",
    "question_topic = question_topic.sort_values(by=['percentage_failed'],ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f'The top 60 failure rates \\n {question_topic.head(60)}\\n')\n",
    "print(f'The bottom 60 failure rates \\n {question_topic.tail(60)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a48a3-5e29-4bc9-ae29-c85c19c49387",
   "metadata": {},
   "source": [
    "# Free Memory For Next Step\n",
    "\n",
    "NB: Optional step if system resources are limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec2735ac-115c-478a-b46d-6c770a11f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xdel sentences_topic_exist\n",
    "# %xdel X \n",
    "# %xdel X_train_df\n",
    "# %xdel X_test_df\n",
    "# %xdel y_train_df\n",
    "# %xdel y_test_df\n",
    "# %xdel X_train\n",
    "# %xdel X_test\n",
    "# %xdel y_train_one_hot\n",
    "# %xdel y_train\n",
    "# %xdel y_test_one_hot\n",
    "# %xdel y_test\n",
    "# %xdel y_pred\n",
    "# %xdel false_predictions\n",
    "# %xdel df_topic_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a5ba5-a931-45b1-bbd4-096fc8d4c008",
   "metadata": {},
   "source": [
    "## Make Predictions For Missing question_topic Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2052611-2997-4b2a-b43e-da411a9cf572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m     5/110555\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57:40\u001b[0m 31ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 21:32:54.018876: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2787730452 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110555/110555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 21:42:09.689432: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2094335568 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Create X input and make predictions\n",
    "X_topic_null_predict = np.array(sequence.pad_sequences(X_topic_null, maxlen=max_len))\n",
    "y_pred_topic_null = model.predict(X_topic_null_predict)\n",
    "\n",
    "# Convert predictions to labels\n",
    "topic_null_predictions = [one_hot_columns[i] for i in np.argmax(y_pred_topic_null, axis=1)]\n",
    "\n",
    "# Insert predictions into 'question_topic' column for null dataframe\n",
    "df_topic_null['question_topic'] = topic_null_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0555e7d-66bb-4a23-9162-e167b3c35d03",
   "metadata": {},
   "source": [
    "# Free Memory For Next Step\n",
    "\n",
    "NB: Optional step if system resources are limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f653521-2b59-4fec-b162-158963a4a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xdel X_topic_null_predict\n",
    "# %xdel y_pred_topic_null\n",
    "# %xdel topic_null_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b97247-398a-40fe-856e-603baa6ce01f",
   "metadata": {},
   "source": [
    "# Export To CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccf1aa7d-d629-4264-b110-54dee3e903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import full datset without missing values for 'question_topic'\n",
    "# NB: Could not do this before due to resource limit on my computer\n",
    "chunks = pd.read_csv('../data/question_topic_valid.csv',\n",
    "                     dtype={'question_user_gender': str, 'response_user_gender': str}, # Removes mixed dtypes error message\n",
    "                     chunksize=100000\n",
    "                    )\n",
    "df_topic_exists = pd.DataFrame()\n",
    "\n",
    "for chunk in chunks:\n",
    "    df_topic_exists = pd.concat([df_topic_exists,chunk], axis=0)\n",
    "\n",
    "\n",
    "# Combine dataset without missing values with the predicted values to recreate the full dataset\n",
    "df_no_missing = pd.concat([df_topic_exists, df_topic_null], axis=0)\n",
    "\n",
    "\n",
    "# Export the predicted values only and the full dataset now with no missing values\n",
    "df_topic_null.to_csv('../data/question_topic_predicted_r1.csv', index=False)\n",
    "df_no_missing.to_csv('../data/question_topic_no_missing_r1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302ce69-b843-42f8-9a56-be94dd2d81a3",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Only a very moderate improvement after relabelling some of the entries in 'question_topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b881cf-c05a-45a0-9faa-f70c4aef8730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
